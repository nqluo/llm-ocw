{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_deployment_id = os.getenv(\"OPENAI_DEPLOYMENT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the text delimited by triple backticks \\ \n",
      "into a single sentence.\n",
      "```\n",
      "You should express what you want a model to do by \\ \n",
      "providing instructions that are as clear and \\ \n",
      "specific as you can possibly make them. \\ \n",
      "This will guide the model towards the desired output, \\ \n",
      "and reduce the chances of receiving irrelevant \\ \n",
      "or incorrect responses. Don't confuse writing a \\ \n",
      "clear prompt with writing a short prompt. \\ \n",
      "In many cases, longer prompts provide more clarity \\ \n",
      "and context for the model, which can lead to \\ \n",
      "more detailed and relevant outputs.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Clear and specific instructions should be provided to guide a model towards the desired output, and longer prompts can provide more clarity and context for the model, leading to more detailed and relevant outputs.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1686927236,\n",
      "  \"id\": \"chatcmpl-7S57k5BJHjkIqzR9NsBgvFJfoCkgy\",\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"prompt_tokens\": 135,\n",
      "    \"total_tokens\": 172\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "response = openai.ChatCompletion.create(\n",
    "    deployment_id=openai_deployment_id,\n",
    "    messages=messages,\n",
    "    temperature=0, # this is the degree of randomness of the model's output\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'object', 'created', 'model', 'choices', 'usage'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<OpenAIObject at 0x10edb2e70> JSON: {\n",
      "  \"finish_reason\": \"stop\",\n",
      "  \"index\": 0,\n",
      "  \"message\": {\n",
      "    \"content\": \"Clear and specific instructions should be provided to guide a model towards the desired output, and longer prompts can provide more clarity and context for the model, leading to more detailed and relevant outputs.\",\n",
      "    \"role\": \"assistant\"\n",
      "  }\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clear and specific instructions should be provided to guide a model towards the desired output, and longer prompts can provide more clarity and context for the model, leading to more detailed and relevant outputs.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<OpenAIObject at 0x10edb3b30> JSON: {\n",
       "   \"completion_tokens\": 37,\n",
       "   \"prompt_tokens\": 135,\n",
       "   \"total_tokens\": 172\n",
       " },\n",
       " 172)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage'], response['usage']['total_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=openai_deployment_id,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To guide a model towards the desired output and reduce the chances of irrelevant or incorrect responses, it is important to provide clear and specific instructions, which may require longer prompts for more clarity and context.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7S4rotYm1PPU9kkGv26UVV5DcM2kn at 0x113ff1d30> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"According to Douglas Adams' book \\\"The Hitchhiker's Guide to the Galaxy,\\\" the answer to the ultimate question of life, the universe, and everything is \\\"42.\\\" However, the meaning behind this answer is never explained in the book.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1686926248,\n",
       "  \"id\": \"chatcmpl-7S4rotYm1PPU9kkGv26UVV5DcM2kn\",\n",
       "  \"model\": \"gpt-35-turbo\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 49,\n",
       "    \"prompt_tokens\": 37,\n",
       "    \"total_tokens\": 86\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"what is the answer to life, the universe, and everything?\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  deployment_id=openai_deployment_id,\n",
    "  messages = messages,\n",
    "  temperature=0.7,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Douglas Adams' book \"The Hitchhiker's Guide to the Galaxy\", the answer to life, the universe, and everything is 42. However, this is a fictional answer and its significance is never fully explained in the book. In reality, the meaning of life and the universe is a philosophical question that has been debated for centuries with no definitive answer.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"what is the answer to life, the universe, and everything?\"\"\"\n",
    "\n",
    "def get_completion(prompt):\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=openai_deployment_id,\n",
    "        messages = messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None)\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top P: \n",
    "\n",
    "Similar to temperature, this controls randomness but uses a different method. Lowering Top P will narrow the modelâ€™s token selection to likelier tokens. Increasing Top P will let the model choose from tokens with both high and low likelihood. Try adjusting temperature or Top P but not both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
